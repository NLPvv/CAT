{
    "data": {
        "train": [
            "train_pl"
        ],
        "dev": [
            "dev_pl"
        ],
        "test": [
            "test_pl"
        ],
        "packing-text-lm": {
            "nj": 4,
            "prune_shorter": 5
        }
    },
    "tokenizer": {
        "type": "SimpleTokenizer",
        "option-init": {
            "dmap": "dict/pl/word_list"
        },
        "|V|": 43748,
        "file": "dict/pl/lm/tokenizer_lm.tknz"
    },
    "commit": "c102b404d8bbce612eecb7e5fa6cb7679609ec5c"
}